---
title: 爬虫系列(四)---保持登陆
categories: 
  - 爬虫
tags:
  - 爬虫
  - python3
  
date: 2018-12-05
mathjax: true

---

在爬取一些网站的时候，需要登陆，而且需要一直保持登陆状态才可以看一些文章，比如知乎、微博，这时我们就需要把我们的登陆信息在请求的时候一并提交，而这个登陆信息就是cookies


```python
import requests 
from  urllib.request import urlopen
# 可以保持同一个cookies，保持登陆状态
#s = s.Session()
#s = s.get("https://weibo.com") # 没有登陆的状态
#print(s.text)
# 不知道为什么用 requests 请求到的网页是中文乱码，而且不能用 bg2313 解码
# 但是用 uurllib 的就没事，这里暂时先不管了
#s = urlopen("https://weibo.com")
#print(s.read().decode("gb2312"))

headers = {
    "Cookie": "太长了，这里就不写了",
    "Host": "weibo.com",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36"

}

s = requests.Session()
s = s.get("这里的地址必须是跟你在Request URL看到的一样",headers=headers)
print(s.text)

```