<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python3,机器学习," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="工作原理是：有一组已经分类好的数据。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。 基本思路12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import numpy as npimpo">
<meta name="keywords" content="python3,机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习实战笔记(六)---kNN算法">
<meta property="og:url" content="http://yoursite.com/2018/10/30/机器学习实战笔记(六)—kNN算法/index.html">
<meta property="og:site_name" content="木叶村">
<meta property="og:description" content="工作原理是：有一组已经分类好的数据。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。 基本思路12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import numpy as npimpo">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-11-21T15:32:06.784Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习实战笔记(六)---kNN算法">
<meta name="twitter:description" content="工作原理是：有一组已经分类好的数据。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。 基本思路12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import numpy as npimpo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/10/30/机器学习实战笔记(六)—kNN算法/"/>





  <title>机器学习实战笔记(六)---kNN算法 | 木叶村</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">木叶村</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/30/机器学习实战笔记(六)—kNN算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Naruto">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/137356299.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="木叶村">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习实战笔记(六)---kNN算法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-30T00:00:00+08:00">
                2018-10-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>工作原理是：有一组已经分类好的数据。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。</p>
<h2 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import operator</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">对未知类别属性的数据集中的每个点依次执行以下操作：</span><br><span class="line">(1) 计算已知类别数据集中的点与当前点之间的距离；</span><br><span class="line">(2) 按照距离递增次序排序；</span><br><span class="line">(3) 选取与当前点距离最小的k个点；</span><br><span class="line">(4) 确定前k个点所在类别的出现频率；</span><br><span class="line">(5) 返回前k个点出现频率最高的类别作为当前点的预测分类。</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line">def classify0(inX, dataSet, labels, k):</span><br><span class="line">    # 返回行数</span><br><span class="line">    dataSetSize = dataSet.shape[0]</span><br><span class="line">    # 在列向量方向上重复inX共1次(横向)，行向量方向上重复inX共dataSetSize次(纵向)</span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize,1)) - dataSet</span><br><span class="line">    sqDiffMat = diffMat**2</span><br><span class="line">    # sum()所有元素相加，sum(0)列相加，sum(1)行相加</span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=1)</span><br><span class="line">    distances = sqDistances**0.5</span><br><span class="line">    # 返回distances中元素从小到大排序后的索引值 </span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    #print(sortedDistIndicies)  </span><br><span class="line">    classCount=&#123;&#125;          </span><br><span class="line">    for i in range(k):</span><br><span class="line">        #print(sortedDistIndicies[i]) # 1,0,3</span><br><span class="line">        #print(labels[sortedDistIndicies[i]]) # A,A,B</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]  </span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1</span><br><span class="line">    #python3中用items()替换python2中的iteritems()</span><br><span class="line">    #key=operator.itemgetter(1)根据字典的值进行排序</span><br><span class="line">    #key=operator.itemgetter(0)根据字典的键进行排序</span><br><span class="line">    #reverse降序排序字典        </span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)</span><br><span class="line">    return sortedClassCount[0][0]</span><br><span class="line"></span><br><span class="line">def createDataSet():</span><br><span class="line">    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])</span><br><span class="line">    labels = [&apos;A&apos;,&apos;A&apos;,&apos;B&apos;,&apos;B&apos;]</span><br><span class="line">    return group, labels</span><br><span class="line">#[[1.  1.1]</span><br><span class="line"> #[1.  1. ]</span><br><span class="line"> #[0.  0. ]</span><br><span class="line"> #[0.  0.1]]</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    group, labels = createDataSet()</span><br><span class="line">    result = classify0([0,0], group, labels, 3)</span><br><span class="line">    print(result) # B</span><br></pre></td></tr></table></figure>
<p>计算$(x_1,y_1)$与$(x_2,y_2)$距离公式：</p>
<script type="math/tex; mode=display">\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}</script><p>这个距离也叫欧式距离。<br>上述代码的<code>classify0</code>函数中17~21行就是计算距离的方法</p>
<h2 id="示例一：改进约会网站的配对效果"><a href="#示例一：改进约会网站的配对效果" class="headerlink" title="示例一：改进约会网站的配对效果"></a>示例一：改进约会网站的配对效果</h2><p><em>为了保证代码完整性，保留了<code>classify0</code>,<code>createDataSet</code>,是下列代码能够作为一个脚本单独运行，同时将多余的注释删除，节省空间</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import operator</span><br><span class="line">from os import listdir</span><br><span class="line">import matplotlib</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib.lines as mlines</span><br><span class="line">from matplotlib.font_manager import FontProperties</span><br><span class="line"></span><br><span class="line">def classify0(inX, dataSet, labels, k):</span><br><span class="line">    dataSetSize = dataSet.shape[0]</span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize,1)) - dataSet</span><br><span class="line">    sqDiffMat = diffMat**2</span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=1)</span><br><span class="line">    distances = sqDistances**0.5</span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    classCount=&#123;&#125;          </span><br><span class="line">    for i in range(k):</span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]  </span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1</span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)</span><br><span class="line">    return sortedClassCount[0][0]</span><br><span class="line"></span><br><span class="line">def createDataSet():</span><br><span class="line">    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])</span><br><span class="line">    labels = [&apos;A&apos;,&apos;A&apos;,&apos;B&apos;,&apos;B&apos;]</span><br><span class="line">    return group, labels</span><br><span class="line"></span><br><span class="line">def file2matrix(filename):</span><br><span class="line">    love_dictionary=&#123;&apos;largeDoses&apos;:3, &apos;smallDoses&apos;:2, &apos;didntLike&apos;:1&#125;</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    arrayOLines = fr.readlines()</span><br><span class="line">    numberOfLines = len(arrayOLines)            #get the number of lines in the file</span><br><span class="line">    returnMat = np.zeros((numberOfLines,3))        #prepare matrix to return</span><br><span class="line">    classLabelVector = []                       #prepare labels return   </span><br><span class="line">    index = 0</span><br><span class="line">    for line in arrayOLines:</span><br><span class="line">        line = line.strip()</span><br><span class="line">        listFromLine = line.split(&apos;\t&apos;)</span><br><span class="line">        returnMat[index,:] = listFromLine[0:3] # 学习numpy之路任重道远啊</span><br><span class="line">        if(listFromLine[-1].isdigit()):</span><br><span class="line">            classLabelVector.append(int(listFromLine[-1]))</span><br><span class="line">        else:</span><br><span class="line">            classLabelVector.append(love_dictionary.get(listFromLine[-1])) # 最后一列就是标签</span><br><span class="line">        index += 1</span><br><span class="line">    return returnMat,classLabelVector</span><br><span class="line"></span><br><span class="line">def autoNorm(dataSet):</span><br><span class="line">    minVals = dataSet.min(0)</span><br><span class="line">    maxVals = dataSet.max(0)</span><br><span class="line">    ranges = maxVals - minVals</span><br><span class="line">    normDataSet = np.zeros(np.shape(dataSet))</span><br><span class="line">    m = dataSet.shape[0]</span><br><span class="line">    normDataSet = dataSet - np.tile(minVals, (m,1))</span><br><span class="line">    normDataSet = normDataSet/np.tile(ranges, (m,1))   #element wise divide</span><br><span class="line">    return normDataSet, ranges, minVals</span><br><span class="line">   </span><br><span class="line">def datingClassTest():</span><br><span class="line">    hoRatio = 0.50      #hold out 10%</span><br><span class="line">    datingDataMat,datingLabels = file2matrix(&apos;datingTestSet2.txt&apos;)       #load data setfrom file</span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    m = normMat.shape[0]</span><br><span class="line">    numTestVecs = int(m*hoRatio)</span><br><span class="line">    errorCount = 0.0</span><br><span class="line">    for i in range(numTestVecs):</span><br><span class="line">	    #前numTestVecs个数据作为测试集,后m-numTestVecs个数据作为训练集</span><br><span class="line">        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)</span><br><span class="line">        print (&quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, datingLabels[i]))</span><br><span class="line">        if (classifierResult != datingLabels[i]): errorCount += 1.0</span><br><span class="line">    print (&quot;the total error rate is: %f&quot; % (errorCount/float(numTestVecs)))</span><br><span class="line">    print (errorCount)</span><br><span class="line">    </span><br><span class="line">def classifyPerson():</span><br><span class="line">    resultList = [&apos;not at all&apos;, &apos;in small doses&apos;, &apos;in large doses&apos;]</span><br><span class="line">    percentTats = float(input(\</span><br><span class="line">                                  &quot;percentage of time spent playing video games?&quot;))</span><br><span class="line">    ffMiles = float(input(&quot;frequent flier miles earned per year?&quot;))</span><br><span class="line">    iceCream = float(input(&quot;liters of ice cream consumed per year?&quot;))</span><br><span class="line">    datingDataMat, datingLabels = file2matrix(&apos;datingTestSet2.txt&apos;)</span><br><span class="line">    normMat, ranges, minVals = autoNorm(datingDataMat)</span><br><span class="line">    inArr = np.array([ffMiles, percentTats, iceCream, ])</span><br><span class="line">    classifierResult = classify0((inArr - \</span><br><span class="line">                                  minVals)/ranges, normMat, datingLabels, 3)</span><br><span class="line">    print (&quot;You will probably like this person: %s&quot; % resultList[classifierResult - 1])</span><br><span class="line"></span><br><span class="line">def showdatas(datingDataMat, datingLabels):</span><br><span class="line">    #设置汉字格式</span><br><span class="line">    font = FontProperties(fname=r&quot;c:\windows\fonts\simsun.ttc&quot;, size=12)</span><br><span class="line">    #将fig画布分隔成1行1列,不共享x轴和y轴,fig画布的大小为(13,8)</span><br><span class="line">    #当nrow=2,nclos=2时,代表fig画布被分为四个区域,axs[0][0]表示第一行第一个区域</span><br><span class="line">    fig, axs = plt.subplots(nrows=2, ncols=2,sharex=False, sharey=False, figsize=(13,8))</span><br><span class="line"></span><br><span class="line">    #numberOfLabels = len(datingLabels)</span><br><span class="line">    LabelsColors = []</span><br><span class="line">    for i in datingLabels:</span><br><span class="line">        if i == 1:</span><br><span class="line">            LabelsColors.append(&apos;black&apos;)</span><br><span class="line">        if i == 2:</span><br><span class="line">            LabelsColors.append(&apos;orange&apos;)</span><br><span class="line">        if i == 3:</span><br><span class="line">            LabelsColors.append(&apos;red&apos;)</span><br><span class="line">    #画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第二列(玩游戏)数据画散点数据,散点大小为15,透明度为0.5</span><br><span class="line">    axs[0][0].scatter(x=datingDataMat[:,0], y=datingDataMat[:,1], color=LabelsColors,s=15, alpha=.5)</span><br><span class="line">    #设置标题,x轴label,y轴label</span><br><span class="line">    axs0_title_text = axs[0][0].set_title(u&apos;每年获得的飞行常客里程数与玩视频游戏所消耗时间占比&apos;,FontProperties=font)</span><br><span class="line">    axs0_xlabel_text = axs[0][0].set_xlabel(u&apos;每年获得的飞行常客里程数&apos;,FontProperties=font)</span><br><span class="line">    axs0_ylabel_text = axs[0][0].set_ylabel(u&apos;玩视频游戏所消耗时间占&apos;,FontProperties=font)</span><br><span class="line">    plt.setp(axs0_title_text, size=9, weight=&apos;bold&apos;, color=&apos;red&apos;) </span><br><span class="line">    plt.setp(axs0_xlabel_text, size=7, weight=&apos;bold&apos;, color=&apos;black&apos;) </span><br><span class="line">    plt.setp(axs0_ylabel_text, size=7, weight=&apos;bold&apos;, color=&apos;black&apos;)</span><br><span class="line"></span><br><span class="line">    #画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5</span><br><span class="line">    axs[0][1].scatter(x=datingDataMat[:,0], y=datingDataMat[:,2], color=LabelsColors,s=15, alpha=.5)</span><br><span class="line">    #设置标题,x轴label,y轴label</span><br><span class="line">    axs1_title_text = axs[0][1].set_title(u&apos;每年获得的飞行常客里程数与每周消费的冰激淋公升数&apos;,FontProperties=font)</span><br><span class="line">    axs1_xlabel_text = axs[0][1].set_xlabel(u&apos;每年获得的飞行常客里程数&apos;,FontProperties=font)</span><br><span class="line">    axs1_ylabel_text = axs[0][1].set_ylabel(u&apos;每周消费的冰激淋公升数&apos;,FontProperties=font)</span><br><span class="line">    plt.setp(axs1_title_text, size=9, weight=&apos;bold&apos;, color=&apos;red&apos;) </span><br><span class="line">    plt.setp(axs1_xlabel_text, size=7, weight=&apos;bold&apos;, color=&apos;black&apos;) </span><br><span class="line">    plt.setp(axs1_ylabel_text, size=7, weight=&apos;bold&apos;, color=&apos;black&apos;)</span><br><span class="line"></span><br><span class="line">    #画出散点图,以datingDataMat矩阵的第二(玩游戏)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5</span><br><span class="line">    axs[1][0].scatter(x=datingDataMat[:,1], y=datingDataMat[:,2], color=LabelsColors,s=15, alpha=.5)</span><br><span class="line">    #设置标题,x轴label,y轴label</span><br><span class="line">    axs2_title_text = axs[1][0].set_title(u&apos;玩视频游戏所消耗时间占比与每周消费的冰激淋公升数&apos;,FontProperties=font)</span><br><span class="line">    axs2_xlabel_text = axs[1][0].set_xlabel(u&apos;玩视频游戏所消耗时间占比&apos;,FontProperties=font)</span><br><span class="line">    axs2_ylabel_text = axs[1][0].set_ylabel(u&apos;每周消费的冰激淋公升数&apos;,FontProperties=font)</span><br><span class="line">    plt.setp(axs2_title_text, size=9, weight=&apos;bold&apos;, color=&apos;red&apos;) </span><br><span class="line">    plt.setp(axs2_xlabel_text, size=7, weight=&apos;bold&apos;, color=&apos;black&apos;) </span><br><span class="line">    plt.setp(axs2_ylabel_text, size=7, weight=&apos;bold&apos;, color=&apos;black&apos;)</span><br><span class="line">    #设置图例</span><br><span class="line">    didntLike = mlines.Line2D([], [], color=&apos;black&apos;, marker=&apos;.&apos;,</span><br><span class="line">                      markersize=6, label=&apos;didntLike&apos;)</span><br><span class="line">    smallDoses = mlines.Line2D([], [], color=&apos;orange&apos;, marker=&apos;.&apos;,</span><br><span class="line">                      markersize=6, label=&apos;smallDoses&apos;)</span><br><span class="line">    largeDoses = mlines.Line2D([], [], color=&apos;red&apos;, marker=&apos;.&apos;,</span><br><span class="line">                      markersize=6, label=&apos;largeDoses&apos;)</span><br><span class="line">    #添加图例</span><br><span class="line">    axs[0][0].legend(handles=[didntLike,smallDoses,largeDoses])</span><br><span class="line">    axs[0][1].legend(handles=[didntLike,smallDoses,largeDoses])</span><br><span class="line">    axs[1][0].legend(handles=[didntLike,smallDoses,largeDoses])</span><br><span class="line">    #显示图片</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 文件有4列 </span><br><span class="line">    # 每年获得的飞行常客里程数</span><br><span class="line">    # 玩视频游戏所耗时间百分比</span><br><span class="line">    # 每周消费的冰淇淋公升数</span><br><span class="line">    # 不喜欢的人 魅力一般的人 极具魅力的人</span><br><span class="line">    #datingDataMat, datingLabels = file2matrix(r&apos;F:\download\machinelearninginaction-master\Ch02\datingTestSet.txt&apos;)</span><br><span class="line">    #showdatas(datingDataMat, datingLabels)</span><br><span class="line">    #datingClassTest</span><br><span class="line">    classifyPerson()</span><br></pre></td></tr></table></figure>
<p>下面我们来进行代码解析，<code>showdatas</code>函数是从网上看到的实质上就是将数据可视化，看不懂可以暂时先不管。<br>首先是<code>file2matrix</code>函数读取数据转换成矩阵格式，最后一列就是标签<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># print(datingDataMat)</span><br><span class="line">[[4.0920000e+04 8.3269760e+00 9.5395200e-01]</span><br><span class="line"> [1.4488000e+04 7.1534690e+00 1.6739040e+00]</span><br><span class="line"> [2.6052000e+04 1.4418710e+00 8.0512400e-01]</span><br><span class="line"> ...</span><br><span class="line"> [2.6575000e+04 1.0650102e+01 8.6662700e-01]</span><br><span class="line"> [4.8111000e+04 9.1345280e+00 7.2804500e-01]</span><br><span class="line"> [4.3757000e+04 7.8826010e+00 1.3324460e+00]]</span><br><span class="line"># print(datingLabels)</span><br><span class="line">[3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3, 1, 2, 3, 3, 3, 1...</span><br></pre></td></tr></table></figure></p>
<p>可视化后应该是计算两点间的距离，但是，三个数值之间的差异很大，也就是说飞行的里程数占的比重比其他的要大，但是我们在这里认为这三个因素都应该是平等的，因此就要对数据进行归一化处理，所以就有了<code>autoNorm</code>函数。</p>
<p>此函数用到的算法是</p>
<script type="math/tex; mode=display">new = (old-min)/(max-min)</script><p>这样就将里程数这个特征值控制在0~1之内，以保证三个特征值的取值范围是一样的，即都有一样的权重。(<em>好像对特征值进行缩放会有损失，暂时先不管</em>)</p>
<p>最后我们就要去验证这个算法的可靠性了，也就是最后一个函数<code>classifyPerson</code></p>
<p>这个示例是用了90%的样本来训练，然后用剩下的10%去做验证，后面的算法中也有更高级的数据分组。这也就是<code>datingClassTest</code>函数的功能了</p>
<hr>
<h2 id="示例二：手写识别系统"><a href="#示例二：手写识别系统" class="headerlink" title="示例二：手写识别系统"></a>示例二：手写识别系统</h2><p>为了使用前面两个例子的分类器，书中将一个32×32的二进制图像变成了文本存储，这里只附上代码，由于方法都一样，就不在赘述<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import operator</span><br><span class="line">from os import listdir</span><br><span class="line">from numpy import zeros</span><br><span class="line"></span><br><span class="line">def classify0(inX, dataSet, labels, k):</span><br><span class="line">    dataSetSize = dataSet.shape[0]</span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize,1)) - dataSet</span><br><span class="line">    sqDiffMat = diffMat**2</span><br><span class="line">    sqDistances = sqDiffMat.sum(axis=1)</span><br><span class="line">    distances = sqDistances**0.5</span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    classCount=&#123;&#125;          </span><br><span class="line">    for i in range(k):</span><br><span class="line">        #print(sortedDistIndicies[i])</span><br><span class="line">        #print(labels[sortedDistIndicies[i]]) </span><br><span class="line">        voteIlabel = labels[sortedDistIndicies[i]]  </span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1</span><br><span class="line">    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)</span><br><span class="line">    return sortedClassCount[0][0]</span><br><span class="line"></span><br><span class="line">def img2vector(filename):</span><br><span class="line">    returnVect = zeros((1,1024))</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    for i in range(32):</span><br><span class="line">        lineStr = fr.readline()</span><br><span class="line">        for j in range(32):</span><br><span class="line">            returnVect[0,32*i+j] = int(lineStr[j])</span><br><span class="line">    return returnVect</span><br><span class="line"></span><br><span class="line">def handwritingClassTest():</span><br><span class="line">    hwLabels = []</span><br><span class="line">    trainingFileList = listdir(r&apos;F:\download\machinelearninginaction-master\Ch02\digits\trainingDigits&apos;)           #load the training set</span><br><span class="line">    m = len(trainingFileList)</span><br><span class="line">    trainingMat = zeros((m,1024))</span><br><span class="line">    for i in range(m):</span><br><span class="line">        fileNameStr = trainingFileList[i]</span><br><span class="line">        fileStr = fileNameStr.split(&apos;.&apos;)[0]     #take off .txt</span><br><span class="line">        classNumStr = int(fileStr.split(&apos;_&apos;)[0])</span><br><span class="line">        hwLabels.append(classNumStr)</span><br><span class="line">        trainingMat[i,:] = img2vector(&apos;F:\\download\\machinelearninginaction-master\\Ch02\digits\\trainingDigits/%s&apos; % fileNameStr)</span><br><span class="line">    testFileList = listdir(r&apos;F:\download\machinelearninginaction-master\Ch02\digits\testDigits&apos;)        #iterate through the test set</span><br><span class="line">    errorCount = 0.0</span><br><span class="line">    mTest = len(testFileList)</span><br><span class="line">    for i in range(mTest):</span><br><span class="line">        fileNameStr = testFileList[i]</span><br><span class="line">        fileStr = fileNameStr.split(&apos;.&apos;)[0]     #take off .txt</span><br><span class="line">        classNumStr = int(fileStr.split(&apos;_&apos;)[0])</span><br><span class="line">        vectorUnderTest = img2vector(&apos;F:\\download\\machinelearninginaction-master\\Ch02\\digits\\testDigits/%s&apos; % fileNameStr)</span><br><span class="line">        classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)</span><br><span class="line">        print (&quot;the classifier came back with: %d, the real answer is: %d&quot; % (classifierResult, classNumStr))</span><br><span class="line">        if (classifierResult != classNumStr): errorCount += 1.0</span><br><span class="line">    print (&quot;\nthe total number of errors is: %d&quot; % errorCount)</span><br><span class="line">    print (&quot;\nthe total error rate is: %f&quot; % (errorCount/float(mTest)))</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    handwritingClassTest()</span><br></pre></td></tr></table></figure></p>
<h2 id="Sklearn简介-重点"><a href="#Sklearn简介-重点" class="headerlink" title="Sklearn简介(重点)"></a>Sklearn简介(重点)</h2><p><a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.neighbors" target="_blank" rel="noopener"><code>sklearn.neighbors</code></a>模块就是k-近邻算法，这里只介绍一个函数<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier" target="_blank" rel="noopener"><code>KNeighborsClassifier</code></a></p>
<p>其他函数和参数等有时间再补充</p>
<p> KNneighborsClassifier参数说明：</p>
<ul>
<li><code>n_neighbors</code>：默认为5，就是k-NN的k的值，选取最近的k个点。 </li>
<li><code>weights</code>：默认是uniform，参数可以是uniform、distance，也可以是用户自己定义的函数。uniform是均等的权重，就说所有的邻近点的权重都是相等的。distance是不均等的权重，距离近的点比距离远的点的影响大。用户自定义的函数，接收距离的数组，返回一组维数相同的权重。</li>
<li><code>algorithm</code>：快速k近邻搜索算法，默认参数为auto，可以理解为算法自己决定合适的搜索算法。除此之外，用户也可以自己指定搜索算法ball_tree、kd_tree、brute方法进行搜索，brute是蛮力搜索，也就是线性扫描，当训练集很大时，计算非常耗时。kd_tree，构造kd树存储数据以便对其进行快速检索的树形数据结构，kd树也就是数据结构中的二叉树。以中值切分构造的树，每个结点是一个超矩形，在维数小于20时效率高。ball tree是为了克服kd树高纬失效而发明的，其构造过程是以质心C和半径r分割样本空间，每个节点是一个超球体。</li>
<li><code>leaf_size</code>：默认是30，这个是构造的kd树和ball树的大小。这个值的设置会影响树构建的速度和搜索速度，同样也影响着存储树所需的内存大小。需要根据问题的性质选择最优的大小。</li>
<li><code>metric</code>：用于距离度量，默认度量是minkowski，也就是p=2的欧氏距离(欧几里德度量)。</li>
<li><code>p</code>：距离度量公式。在上小结，我们使用欧氏距离公式进行距离度量。除此之外，还有其他的度量方法，例如曼哈顿距离。这个参数默认为2，也就是默认使用欧式距离公式进行距离度量。也可以设置为1，使用曼哈顿距离公式进行距离度量。</li>
<li><code>metric_params</code>：距离公式的其他关键参数，这个可以不管，使用默认的None即可。</li>
<li><code>n_jobs</code>：并行处理设置。默认为1，临近点搜索并行工作数。如果为-1，那么CPU的所有cores都用于并行工作。</li>
</ul>
<p>完整代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line">import numpy as np</span><br><span class="line">import operator</span><br><span class="line">from os import listdir</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier as kNN</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">函数说明:将32x32的二进制图像转换为1x1024向量。</span><br><span class="line"></span><br><span class="line">Parameters:</span><br><span class="line">    filename - 文件名</span><br><span class="line">Returns:</span><br><span class="line">    returnVect - 返回的二进制图像的1x1024向量</span><br><span class="line"></span><br><span class="line">Modify:</span><br><span class="line">    2017-07-15</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">def img2vector(filename):</span><br><span class="line">    #创建1x1024零向量</span><br><span class="line">    returnVect = np.zeros((1, 1024))</span><br><span class="line">    #打开文件</span><br><span class="line">    fr = open(filename)</span><br><span class="line">    #按行读取</span><br><span class="line">    for i in range(32):</span><br><span class="line">        #读一行数据</span><br><span class="line">        lineStr = fr.readline()</span><br><span class="line">        #每一行的前32个元素依次添加到returnVect中</span><br><span class="line">        for j in range(32):</span><br><span class="line">            returnVect[0, 32*i+j] = int(lineStr[j])</span><br><span class="line">    #返回转换后的1x1024向量</span><br><span class="line">    return returnVect</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">函数说明:手写数字分类测试</span><br><span class="line"></span><br><span class="line">Parameters:</span><br><span class="line">    无</span><br><span class="line">Returns:</span><br><span class="line">    无</span><br><span class="line"></span><br><span class="line">Modify:</span><br><span class="line">    2017-07-15</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">def handwritingClassTest():</span><br><span class="line">    #测试集的Labels</span><br><span class="line">    hwLabels = []</span><br><span class="line">    #返回trainingDigits目录下的文件名</span><br><span class="line">    trainingFileList = listdir(r&apos;E:\workspace\python\机器学习实战笔记\kNN\Ch02\digits\trainingDigits&apos;)</span><br><span class="line">    #返回文件夹下文件的个数</span><br><span class="line">    m = len(trainingFileList)</span><br><span class="line">    #初始化训练的Mat矩阵,测试集</span><br><span class="line">    trainingMat = np.zeros((m, 1024))</span><br><span class="line">    #从文件名中解析出训练集的类别</span><br><span class="line">    for i in range(m):</span><br><span class="line">        #获得文件的名字</span><br><span class="line">        fileNameStr = trainingFileList[i]</span><br><span class="line">        #获得分类的数字</span><br><span class="line">        classNumber = int(fileNameStr.split(&apos;_&apos;)[0])</span><br><span class="line">        #将获得的类别添加到hwLabels中</span><br><span class="line">        hwLabels.append(classNumber)</span><br><span class="line">        #将每一个文件的1x1024数据存储到trainingMat矩阵中</span><br><span class="line">        trainingMat[i,:] = img2vector(&apos;E:\\workspace\\python\\机器学习实战笔记\\kNN\\Ch02\\digits\\trainingDigits/%s&apos; % (fileNameStr))</span><br><span class="line">    #构建kNN分类器</span><br><span class="line">    neigh = kNN(n_neighbors = 3, algorithm = &apos;auto&apos;)</span><br><span class="line">    #拟合模型, trainingMat为测试矩阵,hwLabels为对应的标签</span><br><span class="line">    neigh.fit(trainingMat, hwLabels)</span><br><span class="line">    #返回testDigits目录下的文件列表</span><br><span class="line">    testFileList = listdir(r&apos;E:\workspace\python\机器学习实战笔记\kNN\Ch02\digits\testDigits&apos;)</span><br><span class="line">    #错误检测计数</span><br><span class="line">    errorCount = 0.0</span><br><span class="line">    #测试数据的数量</span><br><span class="line">    mTest = len(testFileList)</span><br><span class="line">    #从文件中解析出测试集的类别并进行分类测试</span><br><span class="line">    for i in range(mTest):</span><br><span class="line">        #获得文件的名字</span><br><span class="line">        fileNameStr = testFileList[i]</span><br><span class="line">        #获得分类的数字</span><br><span class="line">        classNumber = int(fileNameStr.split(&apos;_&apos;)[0])</span><br><span class="line">        #获得测试集的1x1024向量,用于训练</span><br><span class="line">        vectorUnderTest = img2vector(&apos;E:\\workspace\\python\\机器学习实战笔记\\kNN\\Ch02\\digits\\testDigits/%s&apos; % (fileNameStr))</span><br><span class="line">        #获得预测结果</span><br><span class="line">        # classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)</span><br><span class="line">        classifierResult = neigh.predict(vectorUnderTest)</span><br><span class="line">        print(&quot;分类返回结果为%d\t真实结果为%d&quot; % (classifierResult, classNumber))</span><br><span class="line">        if(classifierResult != classNumber):</span><br><span class="line">            errorCount += 1.0</span><br><span class="line">    print(&quot;总共错了%d个数据\n错误率为%f%%&quot; % (errorCount, errorCount/mTest * 100))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">函数说明:main函数</span><br><span class="line"></span><br><span class="line">Parameters:</span><br><span class="line">    无</span><br><span class="line">Returns:</span><br><span class="line">    无</span><br><span class="line"></span><br><span class="line">Modify:</span><br><span class="line">    2017-07-15</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    handwritingClassTest()</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>参考链接：</strong><a href="http://blog.csdn.net/c406495762" target="_blank" rel="noopener">http://blog.csdn.net/c406495762</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python3/" rel="tag"># python3</a>
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/07/生新基础教程(一)fastq格式/" rel="next" title="生新基础教程(一)：fastq格式">
                <i class="fa fa-chevron-left"></i> 生新基础教程(一)：fastq格式
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/10/30/python3cook系列笔记(一)/" rel="prev" title="python3 cookbook笔记：第一章 数据结构和算法(一)---解压列表">
                python3 cookbook笔记：第一章 数据结构和算法(一)---解压列表 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/137356299.jpg"
               alt="Naruto" />
          <p class="site-author-name" itemprop="name">Naruto</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">46</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">22</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="zhmqsnq90@foxmail.com" target="_blank" title="E-Mail">
                  
                    
                      E-Mail
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本思路"><span class="nav-number">1.</span> <span class="nav-text">基本思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#示例一：改进约会网站的配对效果"><span class="nav-number">2.</span> <span class="nav-text">示例一：改进约会网站的配对效果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#示例二：手写识别系统"><span class="nav-number">3.</span> <span class="nav-text">示例二：手写识别系统</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sklearn简介-重点"><span class="nav-number">4.</span> <span class="nav-text">Sklearn简介(重点)</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Naruto</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
