<!DOCTYPE HTML>
<html lang="zh-CN">
<head>
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="木叶村">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="https://jeweizhong.github.io">
    <!--SEO-->

    <meta name="keywords" content="python3,机器学习" />


    <meta name="description" content="线性模型的基本形式给定由d 个属性描述的示例$\vec x = (x_1,x_2,…x_d)$ ， 其中$x_i$是x 在第i个属性上的取值，线性模型(linear model)试图学得一个通过..." />



<meta name="robots" content="all" />
<meta name="google" content="all" />
<meta name="googlebot" content="all" />
<meta name="verify" content="all" />

    <!--Title-->


<title>机器学习笔记-----线性回归 | 木叶村</title>


    <link rel="alternate" href="/atom.xml" title="木叶村" type="application/atom+xml">


    <link rel="icon" href="/bitbug_favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

</head>


<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  style="background-image:url(http://snippet.shenliyang.com/img/banner.jpg)"  >
    <div class="main-header-box">
        <a class="header-avatar" href="/" title='Naruto'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                <h2> 无人为孤岛，一书一世界 </h2>
            
    	</div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="https://jeweizhong.github.io">木叶村</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/计算机"><i class="fa "></i>计算机</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/生信"><i class="fa "></i>生信</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/数学与统计"><i class="fa "></i>数学与统计</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>时间轴</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="机器学习笔记-----线性回归">
            
	            机器学习笔记-----线性回归
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/数学与统计/">数学与统计</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/python3/">python3</a> <a class="tag-link" href="/tags/机器学习/">机器学习</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/01/14</span>
        </span>
        
    
</div>
            
            
    </div>
    
    <div class="post-body post-content">
        <h2 id="线性模型的基本形式"><a href="#线性模型的基本形式" class="headerlink" title="线性模型的基本形式"></a>线性模型的基本形式</h2><p>给定由d 个属性描述的示例$\vec x = (x_1,x_2,…x_d)$ ， 其中$x_i$是x 在第i个属性上的取值，线性模型(linear model)试图学得一个通过属性的线性组合来进行预测的函数，即:</p>
<script type="math/tex; mode=display">f(\vec x) = \omega_1 x_1 + \omega_2 x_2 +\cdots + \omega_d x_d+d + b  \tag{1}</script><p>写成向量式：</p>
<script type="math/tex; mode=display">f(\vec x ) = \vec\omega^T \vec x  +b \tag{2}</script><h2 id="线性回归原理"><a href="#线性回归原理" class="headerlink" title="线性回归原理"></a>线性回归原理</h2><p>给定数据集$D = {(\vec x_1 ,y_1),(\vec x_2,y_2),\cdots,(\vec x_m,y_m)}$,线性回归就是使用$\vec x$得到一个线性模型是的输出$y’$ 无限接近与$y$，即：</p>
<script type="math/tex; mode=display">f(\vec x ) = \vec\omega^T \vec x + b \simeq y \tag{3}</script><p>这里忽略了下标，即每一个输入$\vec x$ 通过线性回归模型的式子$(3)$得到的$y’$ 都无限接近与数据集中的$y$</p>
<h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>那么如何确定公式$(3)$中的$\vec\omega$和$b$呢?</p>
<p>如果我们的$f(x)$ 与$y$的差别足够小，那么我们就可以带入到公式$(3)$中直接解出$\vec\omega$和$b$来:</p>
<script type="math/tex; mode=display">min\sum|f(x)-y|</script><p>而在实际运用过程中我们一般用平方误差来做性能度量：</p>
<script type="math/tex; mode=display">min \sum(f(x)-y)^2 \tag{4}</script><p>当然也有其他的性能度量方式，只是平方误差这个在线性回归中最常用，这个求解线性回归参数的方法也叫做<strong>最小二乘法</strong></p>
<p>令：</p>
<script type="math/tex; mode=display">E(w,b) = \sum(f(x)-y)^2 \tag{5}</script><p>$E(w,b)$在这里就叫做<strong>代价函数</strong>,吴恩达老师的机器学习课程中稍做了调整：</p>
<script type="math/tex; mode=display">E(w,b) = \frac{1}{2m} \sum_{i=1}^m (f(x)-y)^2 \tag{5}</script><p>我们只需要对$E(w,b)$求偏导就能够求得最小值，这里假设$E(w,b)$是<strong>凸函数</strong>：</p>
<script type="math/tex; mode=display">\frac{\partial E(\omega,b) }{\partial \omega} = 2(\omega \sum_{1=1}^m x_i^2 - \sum_{i=1}^m (y_i-b)x_i)</script><script type="math/tex; mode=display">\frac{\partial E(\omega,b) }{\partial b} = 2(mb - \sum_{i=1}^m (y_i-\omega x_i))</script><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>在讲梯度下降法之前，我们先讲如何直接解出$E(\omega,b)$的最小值：</p>
<p><img src="/myphoto/ml1.png" alt="解方程"></p>
<p><img src="/myphoto/ml2.png" alt="解方程2"></p>
<p><img src="/myphoto/ml3.png" alt="解方程3"></p>
<p>显然这种方法比较复杂，貌似计算量也很大?</p>
<p>下面讲另一种求解$E$最小值的方式，<strong>梯度下降法</strong></p>
<p>该方法的核心思想是同步更新$\vec\omega,b$中每个值：</p>
<script type="math/tex; mode=display">\omega_i = \omega_i -\alpha \frac{\partial E }{\partial \omega_i} ,(i=1,2,...m)</script><p>$\alpha​$称作<strong>学习率</strong>,它的值太小会增加求解的时间，太大会容易造成过拟合。</p>
<p>该方法像是一种穷举，一步一步的找到最小值。</p>
<p>关于这种方法的实现我们将会在逻辑回归中演示，下面讲一下Scikit-Learn关于线性回归的用法。</p>
<h2 id="LinearRegression"><a href="#LinearRegression" class="headerlink" title="LinearRegression"></a>LinearRegression</h2><p>参考sklearn的官方文档中文版：<a href="http://cwiki.apachecn.org/pages/viewpage.action?pageId=12681716" target="_blank" rel="noopener">http://cwiki.apachecn.org/pages/viewpage.action?pageId=12681716</a></p>
<p><code>linear_model.LinearRegression</code>类的成员函数 <code>fit</code> 以数组X和y为输入，并将线性模型的系数$\omega$存储在其成员变量<code>coef_</code> 中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reg = linear_model.LinearRegression()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reg.fit ([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>]], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">LinearRegression(copy_X=<span class="keyword">True</span>, fit_intercept=<span class="keyword">True</span>, n_jobs=<span class="number">1</span>, normalize=<span class="keyword">False</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reg.coef_</span><br><span class="line">array([ <span class="number">0.5</span>,  <span class="number">0.5</span>])</span><br></pre></td></tr></table></figure>
<blockquote>
<p>然而，最小二乘的系数估计依赖于模型特征项的独立性。当特征项相关并且设计矩阵X 的列近似的线性相关时，设计矩阵便接近于一个奇异矩阵(不是满秩，列数过多，会有多个最优解，需要<strong>正则化</strong>)，因此最小二乘估计对观测点中的随机误差变得高度敏感，产生大的方差。</p>
</blockquote>
<h2 id="造轮子"><a href="#造轮子" class="headerlink" title="造轮子"></a>造轮子</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLR</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._a = <span class="keyword">None</span></span><br><span class="line">        self._b = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self,x_train,y_train)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> x_train.ndim == <span class="number">1</span> <span class="keyword">and</span> len(x_train) == len(y_train):</span><br><span class="line">            self._a = (np.mean(x_train) * np.mean(y_train) - np.mean(x_train * y_train)) / \</span><br><span class="line">                      ((np.mean(x_train)**<span class="number">2</span>) - np.mean(x_train**<span class="number">2</span>))</span><br><span class="line">            self._b = np.mean(y_train) - self._a * np.mean(x_train)</span><br><span class="line">            print(self._a,self._b)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self,x_test)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> x_test.ndim == <span class="number">1</span> <span class="keyword">and</span> self._a <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">and</span> self._b <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> self._a * x_test + self._b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    rng = np.random.RandomState(<span class="number">1</span>)</span><br><span class="line">    x_train = <span class="number">10</span> * rng.rand(<span class="number">50</span>) <span class="comment"># 生成均匀分布的50个数</span></span><br><span class="line">    y_train = <span class="number">2</span> * x_train - <span class="number">5</span> + rng.randn(<span class="number">50</span>) <span class="comment"># randn是标准正太分布</span></span><br><span class="line">    x_test = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">1000</span>)</span><br><span class="line">    slr = SimpleLR()</span><br><span class="line">    slr.fit(x_train, y_train)</span><br><span class="line">    y = slr.predict(x_test)</span><br><span class="line">    <span class="comment"># 画图</span></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    plt.scatter(x_train, y_train)</span><br><span class="line">    plt.plot(x_test,y)</span><br><span class="line">    plt.show()</span><br><span class="line">    fig.savefig(<span class="string">'fig.png'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2.027208810360695 -4.998577085553202</span><br></pre></td></tr></table></figure></p>
<p>可见训练效果还是不错的</p>
<p><img src="/myphoto/liner_reg.png" alt="可视化"></p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href="" target="_blank">Snippet</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2019/01/23/ji-qi-xue-xi-bi-ji-logistic-hui-gui/" class="pre-post btn btn-default" title='机器学习笔记-----Logistic回归'>
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">机器学习笔记-----Logistic回归</span>
        </a>
    
    
        <a href="/2018/12/30/python3cookbook-nian-du-zhong-ji-ban-chao-chang-zheng-li/" class="next-post btn btn-default" title='python3 cookbook年度终极版(超长整理)'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">python3 cookbook年度终极版(超长整理)</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
   <p>评论系统未开启，无法评论！</p>

    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#线性模型的基本形式"><span class="toc-text">线性模型的基本形式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#线性回归原理"><span class="toc-text">线性回归原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代价函数"><span class="toc-text">代价函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#梯度下降法"><span class="toc-text">梯度下降法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LinearRegression"><span class="toc-text">LinearRegression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#造轮子"><span class="toc-text">造轮子</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2017
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>